{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNATza+rvhMdi/k5CCQOxNp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neeluu876/nsf-hdr-ml-challenge-2026/blob/main/Monkeys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Activity Forecasting with Cross-Day Generalization\n",
        "\n",
        "This notebook implements a multi-step neural forecasting model for Î¼ECoG data.\n",
        "The focus is on predicting future neural activity while handling day-to-day\n",
        "recording drift through normalization and delta-based prediction."
      ],
      "metadata": {
        "id": "I3fGF_y9dbYT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjxdakTVSNCn",
        "outputId": "51f88d16-c52e-44cb-ff95-fe08c00229da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip -q install timm torchinfo\n",
        "import os, numpy as np, torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchinfo import summary\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content\"\n",
        "\n",
        "print(\"Files in /content:\")\n",
        "for f in sorted(os.listdir(DATA_DIR)):\n",
        "    if f.endswith(\".npz\"):\n",
        "        print(\" -\", f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1y3jzgeUToi",
        "outputId": "4f862936-3e7e-4030-e0b0-27c1984f1aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in /content:\n",
            " - train_data_affi.npz\n",
            " - train_data_affi_2024-03-20_private.npz\n",
            " - train_data_beignet.npz\n",
            " - train_data_beignet_2022-06-01_private.npz\n",
            " - train_data_beignet_2022-06-02_private.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_npz(path):\n",
        "    z = np.load(path)\n",
        "    arr = z[list(z.keys())[0]]\n",
        "    return arr.astype(np.float32)\n",
        "\n",
        "paths = {\n",
        "    \"affi_train\": os.path.join(DATA_DIR, \"train_data_affi.npz\"),\n",
        "    \"affi_val\":   os.path.join(DATA_DIR, \"train_data_affi_2024-03-20_private.npz\"),\n",
        "    \"be_train\":   os.path.join(DATA_DIR, \"train_data_beignet.npz\"),\n",
        "    \"be_val1\":    os.path.join(DATA_DIR, \"train_data_beignet_2022-06-01_private.npz\"),\n",
        "    \"be_val2\":    os.path.join(DATA_DIR, \"train_data_beignet_2022-06-02_private.npz\"),\n",
        "}\n",
        "\n",
        "# Load\n",
        "affi_train = load_npz(paths[\"affi_train\"])\n",
        "affi_val   = load_npz(paths[\"affi_val\"])\n",
        "\n",
        "be_train = load_npz(paths[\"be_train\"])\n",
        "be_val   = np.concatenate([load_npz(paths[\"be_val1\"]), load_npz(paths[\"be_val2\"])], axis=0)\n",
        "\n",
        "print(\"affi_train:\", affi_train.shape, \"affi_val:\", affi_val.shape)\n",
        "print(\"be_train:\",   be_train.shape,   \"be_val:\",   be_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKcGDxmDUwf_",
        "outputId": "9ea1d0d0-3f70-4213-8440-a96c56aa38ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "affi_train: (985, 20, 239, 9) affi_val: (162, 20, 239, 9)\n",
            "be_train: (700, 20, 89, 9) be_val: (158, 20, 89, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralForecastDataset(Dataset):\n",
        "    def __init__(self, data_np, init_steps=10, use_all_features=True, eps=1e-6):\n",
        "        self.data = data_np.astype(np.float32)\n",
        "        self.init_steps = init_steps\n",
        "        self.use_all_features = use_all_features\n",
        "        self.eps = eps\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx]  # (20,C,F)\n",
        "\n",
        "        if not self.use_all_features:\n",
        "            x = x[..., :1]  # only feature 0\n",
        "\n",
        "        x_in  = x[:self.init_steps]      # (10,C,F')\n",
        "        x_out = x[self.init_steps:]      # (10,C,F')\n",
        "\n",
        "        mean = x_in.mean(axis=0, keepdims=True)           # (1,C,F')\n",
        "        std  = x_in.std(axis=0, keepdims=True) + self.eps # (1,C,F')\n",
        "\n",
        "        x_in_n  = (x_in  - mean) / std\n",
        "        x_out_n = (x_out - mean) / std\n",
        "\n",
        "        last = x_in_n[-1:]           # (1,C,F')\n",
        "        y_delta = x_out_n - last     # (10,C,F')\n",
        "\n",
        "        return (\n",
        "            torch.from_numpy(x_in_n),    # (10,C,F')\n",
        "            torch.from_numpy(y_delta),  # (10,C,F')\n",
        "            torch.from_numpy(last),     # (1,C,F')\n",
        "            torch.from_numpy(mean),     # (1,C,F')\n",
        "            torch.from_numpy(std),      # (1,C,F')\n",
        "        )\n"
      ],
      "metadata": {
        "id": "fhHi9PK0UzTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3, dilation=1, dropout=0.15):\n",
        "        super().__init__()\n",
        "        padding = (kernel_size - 1) * dilation\n",
        "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size, padding=padding, dilation=dilation)\n",
        "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size, padding=padding, dilation=dilation)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.downsample = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = y[..., :x.size(-1)]  # crop to keep length\n",
        "        y = F.gelu(y)\n",
        "        y = self.dropout(y)\n",
        "\n",
        "        y = self.conv2(y)\n",
        "        y = y[..., :x.size(-1)]\n",
        "        y = F.gelu(y)\n",
        "        y = self.dropout(y)\n",
        "\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return y + res\n",
        "\n",
        "class TCNForecaster(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=512, levels=5, kernel_size=3, dropout=0.15):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        ch_in = in_dim\n",
        "        for i in range(levels):\n",
        "            dilation = 2**i\n",
        "            layers.append(TemporalBlock(ch_in, hidden, kernel_size=kernel_size, dilation=dilation, dropout=dropout))\n",
        "            ch_in = hidden\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        self.head = nn.Conv1d(hidden, in_dim, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B,10,D)\n",
        "        x = x.transpose(1,2)   # (B,D,10)\n",
        "        y = self.net(x)        # (B,H,10)\n",
        "        y = self.head(y)       # (B,D,10)\n",
        "        return y.transpose(1,2)  # (B,10,D)\n"
      ],
      "metadata": {
        "id": "qzHgLsAIU5Cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, opt):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "    for x_in, y_delta, last, mean, std in loader:\n",
        "        x_in = x_in.to(device)\n",
        "        y_delta = y_delta.to(device)\n",
        "\n",
        "        B,T,C,Fdim = x_in.shape\n",
        "        x_flat = x_in.reshape(B, T, C*Fdim)\n",
        "        y_flat = y_delta.reshape(B, T, C*Fdim)\n",
        "\n",
        "        pred = model(x_flat)\n",
        "        loss = F.mse_loss(pred, y_flat)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        opt.step()\n",
        "\n",
        "        total += loss.item()\n",
        "\n",
        "    return total / max(1, len(loader))\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, loader):\n",
        "    model.eval()\n",
        "    total = 0.0\n",
        "    for x_in, y_delta, last, mean, std in loader:\n",
        "        x_in = x_in.to(device)\n",
        "        y_delta = y_delta.to(device)\n",
        "\n",
        "        B,T,C,Fdim = x_in.shape\n",
        "        x_flat = x_in.reshape(B, T, C*Fdim)\n",
        "        y_flat = y_delta.reshape(B, T, C*Fdim)\n",
        "\n",
        "        pred = model(x_flat)\n",
        "        loss = F.mse_loss(pred, y_flat)\n",
        "        total += loss.item()\n",
        "\n",
        "    return total / max(1, len(loader))\n",
        "\n",
        "@torch.no_grad()\n",
        "def future_feature0_mse(model, loader):\n",
        "    model.eval()\n",
        "    total = 0.0\n",
        "    count = 0\n",
        "\n",
        "    for x_in, y_delta, last, mean, std in loader:\n",
        "        x_in = x_in.to(device)\n",
        "        y_delta = y_delta.to(device)\n",
        "        last = last.to(device)\n",
        "        mean = mean.to(device)\n",
        "        std = std.to(device)\n",
        "\n",
        "        B,T,C,Fdim = x_in.shape\n",
        "        x_flat = x_in.reshape(B, T, C*Fdim)\n",
        "\n",
        "        pred_delta = model(x_flat).reshape(B, T, C, Fdim)\n",
        "        pred_future_n = last + pred_delta\n",
        "        true_future_n = last + y_delta\n",
        "\n",
        "        pred_future = pred_future_n * std + mean\n",
        "        true_future = true_future_n * std + mean\n",
        "\n",
        "        pred0 = pred_future[..., 0]  # (B,10,C)\n",
        "        true0 = true_future[..., 0]\n",
        "\n",
        "        total += F.mse_loss(pred0, true0, reduction=\"sum\").item()\n",
        "        count += pred0.numel()\n",
        "\n",
        "    return total / count\n"
      ],
      "metadata": {
        "id": "aQg7P091U7dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(monkey_name, train_np, val_np, use_all_features=True,\n",
        "                epochs=60, batch_size=32, hidden=512, levels=5, lr=2e-4, wd=1e-4, dropout=0.15):\n",
        "\n",
        "    init_steps = 10\n",
        "    train_ds = NeuralForecastDataset(train_np, init_steps=init_steps, use_all_features=use_all_features)\n",
        "    val_ds   = NeuralForecastDataset(val_np,   init_steps=init_steps, use_all_features=use_all_features)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # infer dims\n",
        "    x0, *_ = train_ds[0]\n",
        "    C = x0.shape[1]\n",
        "    Fdim = x0.shape[2]\n",
        "    D = C * Fdim\n",
        "\n",
        "    model = TCNForecaster(in_dim=D, hidden=hidden, levels=levels, dropout=dropout).to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
        "\n",
        "    save_path = f\"tcn_{monkey_name}.pth\"\n",
        "    best = float(\"inf\")\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        tr = train_one_epoch(model, train_loader, opt)\n",
        "        va = eval_one_epoch(model, val_loader)\n",
        "        va_f0 = future_feature0_mse(model, val_loader)\n",
        "        sched.step()\n",
        "\n",
        "        if va_f0 < best:\n",
        "            best = va_f0\n",
        "            torch.save({\n",
        "                \"state_dict\": model.state_dict(),\n",
        "                \"monkey_name\": monkey_name,\n",
        "                \"use_all_features\": use_all_features,\n",
        "                \"init_steps\": init_steps,\n",
        "                \"trained_C\": C,\n",
        "                \"trained_Fdim\": Fdim,\n",
        "                \"trained_D\": D,\n",
        "                \"hidden\": hidden,\n",
        "                \"levels\": levels,\n",
        "                \"dropout\": dropout,\n",
        "            }, save_path)\n",
        "\n",
        "        if ep % 5 == 0 or ep == epochs-1:\n",
        "            print(f\"[{monkey_name}] ep {ep:02d} train_mse(delta)={tr:.6f} \"\n",
        "                  f\"val_mse(delta)={va:.6f} val_future_f0_mse={va_f0:.6f} best={best:.6f}\")\n",
        "\n",
        "    print(\"Saved best:\", save_path)\n",
        "    return save_path\n"
      ],
      "metadata": {
        "id": "uel4xmYgU-FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "be_ckpt = train_model(\n",
        "    monkey_name=\"beignet\",\n",
        "    train_np=be_train,\n",
        "    val_np=be_val,\n",
        "    use_all_features=True,\n",
        "    epochs=60,\n",
        "    batch_size=32,\n",
        "    hidden=512,\n",
        "    levels=5,\n",
        "    lr=2e-4,\n",
        "    wd=1e-4,\n",
        "    dropout=0.15\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJFnyk01VF5G",
        "outputId": "5b7b2646-54bd-42e7-92df-6ad79180ceb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[beignet] ep 00 train_mse(delta)=11.579854 val_mse(delta)=18.320062 val_future_f0_mse=69491.913640 best=69491.913640\n",
            "[beignet] ep 05 train_mse(delta)=10.300733 val_mse(delta)=18.355276 val_future_f0_mse=64090.525729 best=64090.525729\n",
            "[beignet] ep 10 train_mse(delta)=8.917003 val_mse(delta)=18.583972 val_future_f0_mse=65564.767686 best=64090.525729\n",
            "[beignet] ep 15 train_mse(delta)=8.142272 val_mse(delta)=18.601347 val_future_f0_mse=68425.131674 best=64090.525729\n",
            "[beignet] ep 20 train_mse(delta)=7.555680 val_mse(delta)=18.775513 val_future_f0_mse=69865.545840 best=64090.525729\n",
            "[beignet] ep 25 train_mse(delta)=7.085939 val_mse(delta)=18.809107 val_future_f0_mse=70054.267103 best=64090.525729\n",
            "[beignet] ep 30 train_mse(delta)=6.738588 val_mse(delta)=18.871667 val_future_f0_mse=69755.492419 best=64090.525729\n",
            "[beignet] ep 35 train_mse(delta)=6.462330 val_mse(delta)=18.833643 val_future_f0_mse=69730.397611 best=64090.525729\n",
            "[beignet] ep 40 train_mse(delta)=6.263483 val_mse(delta)=18.877181 val_future_f0_mse=70669.464486 best=64090.525729\n",
            "[beignet] ep 45 train_mse(delta)=6.125172 val_mse(delta)=18.872785 val_future_f0_mse=70793.645058 best=64090.525729\n",
            "[beignet] ep 50 train_mse(delta)=6.056374 val_mse(delta)=18.887338 val_future_f0_mse=70922.979491 best=64090.525729\n",
            "[beignet] ep 55 train_mse(delta)=6.017638 val_mse(delta)=18.870337 val_future_f0_mse=70676.455241 best=64090.525729\n",
            "[beignet] ep 59 train_mse(delta)=6.008445 val_mse(delta)=18.883686 val_future_f0_mse=70745.568141 best=64090.525729\n",
            "Saved best: tcn_beignet.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "affi_ckpt = train_model(\n",
        "    monkey_name=\"affi\",\n",
        "    train_np=affi_train,\n",
        "    val_np=affi_val,\n",
        "    use_all_features=True,\n",
        "    epochs=60,\n",
        "    batch_size=16,   # smaller to avoid OOM\n",
        "    hidden=512,\n",
        "    levels=5,\n",
        "    lr=2e-4,\n",
        "    wd=1e-4,\n",
        "    dropout=0.15\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYLCn5RmVPQi",
        "outputId": "9f811a76-f44c-4885-b317-5a2b8bcde70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[affi] ep 00 train_mse(delta)=13.696932 val_mse(delta)=13.723002 val_future_f0_mse=62698.405496 best=62698.405496\n",
            "[affi] ep 05 train_mse(delta)=11.614823 val_mse(delta)=14.932104 val_future_f0_mse=61763.957229 best=59531.340751\n",
            "[affi] ep 10 train_mse(delta)=10.223691 val_mse(delta)=14.454315 val_future_f0_mse=64737.936960 best=57095.671140\n",
            "[affi] ep 15 train_mse(delta)=9.219204 val_mse(delta)=14.312815 val_future_f0_mse=56419.205124 best=56419.205124\n",
            "[affi] ep 20 train_mse(delta)=8.288452 val_mse(delta)=14.269698 val_future_f0_mse=61208.918973 best=56419.205124\n",
            "[affi] ep 25 train_mse(delta)=7.653831 val_mse(delta)=14.303302 val_future_f0_mse=60432.249434 best=56419.205124\n",
            "[affi] ep 30 train_mse(delta)=7.119524 val_mse(delta)=14.341990 val_future_f0_mse=59165.721866 best=56419.205124\n",
            "[affi] ep 35 train_mse(delta)=6.717621 val_mse(delta)=14.331668 val_future_f0_mse=59254.636211 best=56419.205124\n",
            "[affi] ep 40 train_mse(delta)=6.416847 val_mse(delta)=14.345446 val_future_f0_mse=58841.986797 best=56419.205124\n",
            "[affi] ep 45 train_mse(delta)=6.232619 val_mse(delta)=14.376072 val_future_f0_mse=58857.241800 best=56419.205124\n",
            "[affi] ep 50 train_mse(delta)=6.114545 val_mse(delta)=14.365450 val_future_f0_mse=58504.409029 best=56419.205124\n",
            "[affi] ep 55 train_mse(delta)=6.068621 val_mse(delta)=14.361033 val_future_f0_mse=58410.133747 best=56419.205124\n",
            "[affi] ep 59 train_mse(delta)=6.073059 val_mse(delta)=14.355523 val_future_f0_mse=58258.646914 best=56419.205124\n",
            "Saved best: tcn_affi.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3, dilation=1, dropout=0.0):\n",
        "        super().__init__()\n",
        "        padding = (kernel_size - 1) * dilation\n",
        "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size, padding=padding, dilation=dilation)\n",
        "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size, padding=padding, dilation=dilation)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.downsample = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = y[..., :x.size(-1)]\n",
        "        y = F.gelu(y)\n",
        "        y = self.dropout(y)\n",
        "\n",
        "        y = self.conv2(y)\n",
        "        y = y[..., :x.size(-1)]\n",
        "        y = F.gelu(y)\n",
        "        y = self.dropout(y)\n",
        "\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return y + res\n",
        "\n",
        "class TCNForecaster(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=512, levels=5, kernel_size=3, dropout=0.0):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        ch_in = in_dim\n",
        "        for i in range(levels):\n",
        "            dilation = 2**i\n",
        "            layers.append(TemporalBlock(ch_in, hidden, kernel_size=kernel_size, dilation=dilation, dropout=dropout))\n",
        "            ch_in = hidden\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        self.head = nn.Conv1d(hidden, in_dim, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1,2)   # (B,D,10)\n",
        "        y = self.net(x)\n",
        "        y = self.head(y)\n",
        "        return y.transpose(1,2)  # (B,10,D)\n",
        "\n",
        "def _normalize_per_sample(x_in, eps=1e-6):\n",
        "    # x_in: (N,10,C,F)\n",
        "    mean = x_in.mean(axis=1, keepdims=True)  # (N,1,C,F)\n",
        "    std  = x_in.std(axis=1, keepdims=True) + eps\n",
        "    return (x_in - mean) / std, mean, std\n",
        "\n",
        "class Model:\n",
        "    def __init__(self, monkey_name=\"\"):\n",
        "        self.monkey_name = monkey_name\n",
        "        self.init_steps = 10\n",
        "        self.use_all_features = True\n",
        "        self.model = None\n",
        "        self.trained_C = None\n",
        "        self.trained_Fdim = None\n",
        "\n",
        "    def load(self):\n",
        "        if self.monkey_name == \"affi\":\n",
        "            w = \"tcn_affi.pth\"\n",
        "        elif self.monkey_name == \"beignet\":\n",
        "            w = \"tcn_beignet.pth\"\n",
        "        else:\n",
        "            raise ValueError(f\"No such monkey: {self.monkey_name}\")\n",
        "\n",
        "        path = os.path.join(os.path.dirname(__file__), w)\n",
        "        ckpt = torch.load(path, map_location=\"cpu\")\n",
        "\n",
        "        self.trained_C = int(ckpt[\"trained_C\"])\n",
        "        self.trained_Fdim = int(ckpt[\"trained_Fdim\"])\n",
        "        D = int(ckpt[\"trained_D\"])\n",
        "        hidden = int(ckpt.get(\"hidden\", 512))\n",
        "        levels = int(ckpt.get(\"levels\", 5))\n",
        "\n",
        "        self.model = TCNForecaster(in_dim=D, hidden=hidden, levels=levels, dropout=0.0).to(DEVICE)\n",
        "        self.model.load_state_dict(ckpt[\"state_dict\"], strict=True)\n",
        "        self.model.eval()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict(self, X):\n",
        "        X = np.asarray(X, dtype=np.float32)\n",
        "        N,T,C_in,F_in = X.shape\n",
        "        if T != 20:\n",
        "            raise ValueError(\"Expected 20 time steps\")\n",
        "\n",
        "        out = np.zeros((N, 20, C_in), dtype=np.float32)\n",
        "        out[:, :10, :] = X[:, :10, :, 0]      # copy observed\n",
        "        out[:, 10:, :] = X[:, 9:10, :, 0]     # fallback persistence\n",
        "\n",
        "        if self.use_all_features:\n",
        "            Xf = X\n",
        "        else:\n",
        "            Xf = X[..., :1]\n",
        "\n",
        "        C_common = min(C_in, self.trained_C)\n",
        "\n",
        "        x_in = Xf[:, :10, :C_common, :self.trained_Fdim]  # (N,10,C,F')\n",
        "        x_in_n, mean, std = _normalize_per_sample(x_in)\n",
        "\n",
        "        last = x_in_n[:, -1:, :, :]  # (N,1,C,F')\n",
        "        Nn,_,Cc,Fc = x_in_n.shape\n",
        "\n",
        "        x_flat = torch.from_numpy(x_in_n).to(DEVICE).reshape(Nn, 10, Cc*Fc)\n",
        "        pred_delta = self.model(x_flat).reshape(Nn, 10, Cc, Fc).cpu().numpy()\n",
        "\n",
        "        pred_future_n = last + pred_delta\n",
        "        pred_future = pred_future_n * std + mean\n",
        "\n",
        "        out[:, 10:, :C_common] = pred_future[..., 0]\n",
        "        return out\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d8V66FnVSjv",
        "outputId": "4e3c0a81-0590-4686-face-eed01c115157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    }
  ]
}